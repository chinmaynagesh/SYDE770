{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "lsMdJkSq7tWA"
      },
      "outputs": [],
      "source": [
        "from ultralytics import YOLO\n",
        "import cv2\n",
        "import os\n",
        "import glob\n",
        "import os\n",
        "import glob\n",
        "import random\n",
        "import shutil\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from ultralytics import YOLO\n",
        "import torch\n",
        "from pathlib import Path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/Users/sahilbodkhe/Desktop/Experiment4/SYDE770\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "print(os.getcwd())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "JTEhhoPOIK0A"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total Images: 1669\n",
            "Class Distribution: class\n",
            "1    1026\n",
            "0     643\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Paths\n",
        "BASE_DIR = \"/Users/sahilbodkhe/Desktop/Experiment4/SYDE770/Normal_cups\"  # Change to your dataset path\n",
        "IMAGE_DIR = os.path.join(BASE_DIR, \"images\")\n",
        "LABEL_DIR = os.path.join(BASE_DIR, \"data\")\n",
        "OUTPUT_DIR = os.path.join(BASE_DIR, \"yolo_dataset\")\n",
        "MODEL_PATH = \"yolov5\"  # Change if using another YOLOv5 model\n",
        "\n",
        "# Create output directories\n",
        "os.makedirs(os.path.join(OUTPUT_DIR, \"train\", \"images\"), exist_ok=True)\n",
        "os.makedirs(os.path.join(OUTPUT_DIR, \"train\", \"labels\"), exist_ok=True)\n",
        "os.makedirs(os.path.join(OUTPUT_DIR, \"val\", \"images\"), exist_ok=True)\n",
        "os.makedirs(os.path.join(OUTPUT_DIR, \"val\", \"labels\"), exist_ok=True)\n",
        "\n",
        "# Load images & labels\n",
        "image_paths = glob.glob(os.path.join(IMAGE_DIR, \"*\"))\n",
        "image_list = []\n",
        "labels = []\n",
        "\n",
        "for img_path in image_paths:\n",
        "    base_name = os.path.splitext(os.path.basename(img_path))[0]\n",
        "    label_path = os.path.join(LABEL_DIR, base_name + \".txt\")\n",
        "\n",
        "    if os.path.exists(label_path) and os.path.getsize(label_path) > 0:\n",
        "        with open(label_path, \"r\") as file:\n",
        "            label_data = file.readlines()\n",
        "            class_ids = [int(line.split()[0]) for line in label_data]\n",
        "            label_class = 1 if 1 in class_ids else 0  # If a Tim Hortons cup is present, label as 1\n",
        "    else:\n",
        "        label_class = 0  # No annotation means it's a normal cup (background class)\n",
        "\n",
        "    image_list.append((img_path, label_path))\n",
        "    labels.append(label_class)\n",
        "\n",
        "# Convert to DataFrame for processing\n",
        "df = pd.DataFrame(image_list, columns=[\"image\", \"label\"])\n",
        "df[\"class\"] = labels\n",
        "\n",
        "# Print dataset summary\n",
        "print(f\"Total Images: {len(df)}\")\n",
        "print(f\"Class Distribution: {df['class'].value_counts()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training completed! Model saved in YOLO output folder.\n"
          ]
        }
      ],
      "source": [
        "import shutil\n",
        "import os\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "# Create necessary directories and copy data (train/validation)\n",
        "OUTPUT_DIR = \"C:/Users/Chinmay Nagesh/Desktop/Yolo/SYDE770/Normal_cups/yolo_dataset\"\n",
        "\n",
        "# Stratified K-Fold Cross Validation (Keep Class Balance)\n",
        "k_folds = 5\n",
        "skf = StratifiedKFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
        "\n",
        "# Select one fold as validation (80-20 Split)\n",
        "for train_idx, val_idx in skf.split(df[\"image\"], df[\"class\"]):\n",
        "    train_data = df.iloc[train_idx]\n",
        "    val_data = df.iloc[val_idx]\n",
        "    break  # We only need the first split\n",
        "\n",
        "# Function to copy files\n",
        "def copy_files(data, split):\n",
        "    for _, row in data.iterrows():\n",
        "        shutil.copy(row[\"image\"], os.path.join(OUTPUT_DIR, split, \"images\", os.path.basename(row[\"image\"])))\n",
        "\n",
        "        if os.path.exists(row[\"label\"]) and os.path.getsize(row[\"label\"]) > 0:\n",
        "            shutil.copy(row[\"label\"], os.path.join(OUTPUT_DIR, split, \"labels\", os.path.basename(row[\"label\"])))\n",
        "        else:\n",
        "            # Create an empty label file if no annotation exists\n",
        "            open(os.path.join(OUTPUT_DIR, split, \"labels\", os.path.basename(row[\"label\"])), 'w').close()\n",
        "\n",
        "copy_files(train_data, \"train\")\n",
        "copy_files(val_data, \"val\")\n",
        "\n",
        "# Create YOLO dataset.yaml file\n",
        "yaml_content = f\"\"\"\n",
        "path: C:/Users/Chinmay Nagesh/Desktop/Yolo/SYDE770/Normal_cups/yolo_dataset\n",
        "train: train/images\n",
        "val: val/images\n",
        "nc: 2\n",
        "names: [\"Normal Cup\", \"Tim Hortons Cup\"]\n",
        "\"\"\"\n",
        "\n",
        "yaml_path = \"C:/Users/Chinmay Nagesh/Desktop/Yolo/SYDE770/Normal_cups/yolo_dataset/dataset.yaml\"\n",
        "with open(yaml_path, \"w\") as f:\n",
        "    f.write(yaml_content)\n",
        "\n",
        "# Train YOLOv5 (No MLflow integration in this cell)\n",
        "command = r'python yolov5/train.py --imgsz 320 --batch-size 32 --epochs 5 --data \"C:/Users/Chinmay Nagesh/Desktop/Yolo/SYDE770/Normal_cups/yolo_dataset/dataset.yaml\" --weights yolov5s.pt --device cpu --freeze 10'\n",
        "os.system(command)\n",
        "\n",
        "print(\"Training completed! Model saved in YOLO output folder.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "# Define constants\n",
        "OUTPUT_DIR = \"/Users/sahilbodkhe/Desktop/Experiment4/SYDE770/Normal_cups/yolo_dataset\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "TRAIN_DIR = os.path.join(OUTPUT_DIR, \"train\")\n",
        "VAL_DIR = os.path.join(OUTPUT_DIR, \"val\")\n",
        "\n",
        "# Ensure necessary directories exist\n",
        "def create_dirs():\n",
        "    for split in [\"train\", \"val\"]:\n",
        "        os.makedirs(os.path.join(OUTPUT_DIR, split, \"images\"), exist_ok=True)\n",
        "        os.makedirs(os.path.join(OUTPUT_DIR, split, \"labels\"), exist_ok=True)\n",
        "\n",
        "\n",
        "\n",
        "# Stratified K-Fold Split\n",
        "k_folds = 5\n",
        "skf = StratifiedKFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
        "\n",
        "for train_idx, val_idx in skf.split(df[\"image\"], df[\"class\"]):\n",
        "    train_data = df.iloc[train_idx]\n",
        "    val_data = df.iloc[val_idx]\n",
        "    break  # Only using the first split\n",
        "\n",
        "# Function to copy files\n",
        "def copy_files(data, split):\n",
        "    for _, row in data.iterrows():\n",
        "        img_src = row[\"image\"]\n",
        "        label_src = row[\"label\"]\n",
        "        \n",
        "        img_dst = os.path.join(OUTPUT_DIR, split, \"images\", os.path.basename(img_src))\n",
        "        label_dst = os.path.join(OUTPUT_DIR, split, \"labels\", os.path.basename(label_src))\n",
        "        \n",
        "        if os.path.exists(img_src):\n",
        "            shutil.copy(img_src, img_dst)\n",
        "        else:\n",
        "            print(f\"Warning: Image file not found - {img_src}\")\n",
        "        \n",
        "        if os.path.exists(label_src) and os.path.getsize(label_src) > 0:\n",
        "            shutil.copy(label_src, label_dst)\n",
        "        else:\n",
        "            open(label_dst, 'w').close()  # Create empty label if missing\n",
        "\n",
        "# Create required directories\n",
        "create_dirs()\n",
        "copy_files(train_data, \"train\")\n",
        "copy_files(val_data, \"val\")\n",
        "\n",
        "# Generate dataset.yaml file\n",
        "yaml_content = f\"\"\"\n",
        "path: {OUTPUT_DIR}\n",
        "train: train/images\n",
        "val: val/images\n",
        "nc: 2\n",
        "names: [\"Normal Cup\", \"Tim Hortons Cup\"]\n",
        "\"\"\"\n",
        "\n",
        "yaml_path = os.path.join(OUTPUT_DIR, \"dataset.yaml\")\n",
        "with open(yaml_path, \"w\") as f:\n",
        "    f.write(yaml_content)\n",
        "\n",
        "# Train YOLOv5\n",
        "command = (\n",
        "    f'python3 /Users/sahilbodkhe/Desktop/Experiment4/SYDE770/yolov5/train.py --imgsz 320 --batch-size 32 --epochs 5 '\n",
        "    f'--data \"{yaml_path}\" --weights yolov5s.pt --device mps --freeze 10'\n",
        ")\n",
        "\n",
        "exit_code = os.system(command)\n",
        "if exit_code != 0:\n",
        "    print(\"Error: YOLO training failed. Check the logs for details.\")\n",
        "else:\n",
        "    print(\"Training completed! Model saved in YOLO output folder.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "torch.mps.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(torch.backends.mps.is_available())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n",
            "True\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(torch.backends.mps.is_available())  # True if Metal is available\n",
        "print(torch.backends.mps.is_built())  # True if Metal is built into PyTorch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "New https://pypi.org/project/ultralytics/8.3.89 available 😃 Update with 'pip install -U ultralytics'\n",
            "Ultralytics 8.3.88 🚀 Python-3.11.9 torch-2.6.0 MPS (Apple M3)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8s.pt, data=/Users/sahilbodkhe/Desktop/Experiment4/SYDE770/Normal_cups/yolo_dataset/dataset.yaml, epochs=10, time=None, patience=100, batch=64, imgsz=416, save=True, save_period=-1, cache=False, device=mps, workers=8, project=None, name=train10, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=10, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train10\n",
            "Overriding model.yaml nc=80 with nc=2\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
            "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
            "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
            "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
            " 22        [15, 18, 21]  1   2116822  ultralytics.nn.modules.head.Detect           [2, [128, 256, 512]]          \n",
            "Model summary: 129 layers, 11,136,374 parameters, 11,136,358 gradients, 28.6 GFLOPs\n",
            "\n",
            "Transferred 349/355 items from pretrained weights\n",
            "Freezing layer 'model.0.conv.weight'\n",
            "Freezing layer 'model.0.bn.weight'\n",
            "Freezing layer 'model.0.bn.bias'\n",
            "Freezing layer 'model.1.conv.weight'\n",
            "Freezing layer 'model.1.bn.weight'\n",
            "Freezing layer 'model.1.bn.bias'\n",
            "Freezing layer 'model.2.cv1.conv.weight'\n",
            "Freezing layer 'model.2.cv1.bn.weight'\n",
            "Freezing layer 'model.2.cv1.bn.bias'\n",
            "Freezing layer 'model.2.cv2.conv.weight'\n",
            "Freezing layer 'model.2.cv2.bn.weight'\n",
            "Freezing layer 'model.2.cv2.bn.bias'\n",
            "Freezing layer 'model.2.m.0.cv1.conv.weight'\n",
            "Freezing layer 'model.2.m.0.cv1.bn.weight'\n",
            "Freezing layer 'model.2.m.0.cv1.bn.bias'\n",
            "Freezing layer 'model.2.m.0.cv2.conv.weight'\n",
            "Freezing layer 'model.2.m.0.cv2.bn.weight'\n",
            "Freezing layer 'model.2.m.0.cv2.bn.bias'\n",
            "Freezing layer 'model.3.conv.weight'\n",
            "Freezing layer 'model.3.bn.weight'\n",
            "Freezing layer 'model.3.bn.bias'\n",
            "Freezing layer 'model.4.cv1.conv.weight'\n",
            "Freezing layer 'model.4.cv1.bn.weight'\n",
            "Freezing layer 'model.4.cv1.bn.bias'\n",
            "Freezing layer 'model.4.cv2.conv.weight'\n",
            "Freezing layer 'model.4.cv2.bn.weight'\n",
            "Freezing layer 'model.4.cv2.bn.bias'\n",
            "Freezing layer 'model.4.m.0.cv1.conv.weight'\n",
            "Freezing layer 'model.4.m.0.cv1.bn.weight'\n",
            "Freezing layer 'model.4.m.0.cv1.bn.bias'\n",
            "Freezing layer 'model.4.m.0.cv2.conv.weight'\n",
            "Freezing layer 'model.4.m.0.cv2.bn.weight'\n",
            "Freezing layer 'model.4.m.0.cv2.bn.bias'\n",
            "Freezing layer 'model.4.m.1.cv1.conv.weight'\n",
            "Freezing layer 'model.4.m.1.cv1.bn.weight'\n",
            "Freezing layer 'model.4.m.1.cv1.bn.bias'\n",
            "Freezing layer 'model.4.m.1.cv2.conv.weight'\n",
            "Freezing layer 'model.4.m.1.cv2.bn.weight'\n",
            "Freezing layer 'model.4.m.1.cv2.bn.bias'\n",
            "Freezing layer 'model.5.conv.weight'\n",
            "Freezing layer 'model.5.bn.weight'\n",
            "Freezing layer 'model.5.bn.bias'\n",
            "Freezing layer 'model.6.cv1.conv.weight'\n",
            "Freezing layer 'model.6.cv1.bn.weight'\n",
            "Freezing layer 'model.6.cv1.bn.bias'\n",
            "Freezing layer 'model.6.cv2.conv.weight'\n",
            "Freezing layer 'model.6.cv2.bn.weight'\n",
            "Freezing layer 'model.6.cv2.bn.bias'\n",
            "Freezing layer 'model.6.m.0.cv1.conv.weight'\n",
            "Freezing layer 'model.6.m.0.cv1.bn.weight'\n",
            "Freezing layer 'model.6.m.0.cv1.bn.bias'\n",
            "Freezing layer 'model.6.m.0.cv2.conv.weight'\n",
            "Freezing layer 'model.6.m.0.cv2.bn.weight'\n",
            "Freezing layer 'model.6.m.0.cv2.bn.bias'\n",
            "Freezing layer 'model.6.m.1.cv1.conv.weight'\n",
            "Freezing layer 'model.6.m.1.cv1.bn.weight'\n",
            "Freezing layer 'model.6.m.1.cv1.bn.bias'\n",
            "Freezing layer 'model.6.m.1.cv2.conv.weight'\n",
            "Freezing layer 'model.6.m.1.cv2.bn.weight'\n",
            "Freezing layer 'model.6.m.1.cv2.bn.bias'\n",
            "Freezing layer 'model.7.conv.weight'\n",
            "Freezing layer 'model.7.bn.weight'\n",
            "Freezing layer 'model.7.bn.bias'\n",
            "Freezing layer 'model.8.cv1.conv.weight'\n",
            "Freezing layer 'model.8.cv1.bn.weight'\n",
            "Freezing layer 'model.8.cv1.bn.bias'\n",
            "Freezing layer 'model.8.cv2.conv.weight'\n",
            "Freezing layer 'model.8.cv2.bn.weight'\n",
            "Freezing layer 'model.8.cv2.bn.bias'\n",
            "Freezing layer 'model.8.m.0.cv1.conv.weight'\n",
            "Freezing layer 'model.8.m.0.cv1.bn.weight'\n",
            "Freezing layer 'model.8.m.0.cv1.bn.bias'\n",
            "Freezing layer 'model.8.m.0.cv2.conv.weight'\n",
            "Freezing layer 'model.8.m.0.cv2.bn.weight'\n",
            "Freezing layer 'model.8.m.0.cv2.bn.bias'\n",
            "Freezing layer 'model.9.cv1.conv.weight'\n",
            "Freezing layer 'model.9.cv1.bn.weight'\n",
            "Freezing layer 'model.9.cv1.bn.bias'\n",
            "Freezing layer 'model.9.cv2.conv.weight'\n",
            "Freezing layer 'model.9.cv2.bn.weight'\n",
            "Freezing layer 'model.9.cv2.bn.bias'\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/sahilbodkhe/Desktop/Experiment4/SYDE770/Normal_cups/yolo_dataset/train/labels.cache... 1335 images, 1 backgrounds, 0 corrupt: 100%|██████████| 1335/1335 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /Users/sahilbodkhe/Desktop/Experiment4/SYDE770/Normal_cups/yolo_dataset/train/images/GenAI_Img_4_2.jpeg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /Users/sahilbodkhe/Desktop/Experiment4/SYDE770/Normal_cups/yolo_dataset/train/images/a_plain_red_coloured_tim_hortons_cup-19.jpeg: 1 duplicate labels removed\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/sahilbodkhe/Desktop/Experiment4/SYDE770/Normal_cups/yolo_dataset/val/labels.cache... 334 images, 0 backgrounds, 0 corrupt: 100%|██████████| 334/334 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Plotting labels to runs/detect/train10/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mMLflow: \u001b[0mlogging run_id(9f41e2e316dd48ba93ad28a4e2e2ded2) to runs/mlflow\n",
            "\u001b[34m\u001b[1mMLflow: \u001b[0mview at http://127.0.0.1:5000 with 'mlflow server --backend-store-uri runs/mlflow'\n",
            "\u001b[34m\u001b[1mMLflow: \u001b[0mdisable with 'yolo settings mlflow=False'\n",
            "Image sizes 416 train, 416 val\n",
            "Using 0 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train10\u001b[0m\n",
            "Starting training for 10 epochs...\n",
            "Closing dataloader mosaic\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       1/10      7.84G     0.7426      1.836      1.171         81        416: 100%|██████████| 21/21 [20:51<00:00, 59.60s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  33%|███▎      | 1/3 [00:41<01:23, 41.51s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING ⚠️ NMS time limit 8.400s exceeded\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [02:16<00:00, 45.65s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        334        503      0.811      0.779      0.844      0.756\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       2/10      8.03G     0.5579     0.8143     0.9975         96        416: 100%|██████████| 21/21 [14:04<00:00, 40.22s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING ⚠️ NMS time limit 8.400s exceeded\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  33%|███▎      | 1/3 [00:49<01:39, 49.90s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING ⚠️ NMS time limit 8.400s exceeded\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [02:23<00:00, 47.71s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        334        503      0.783      0.282      0.298      0.241\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       3/10      8.18G      0.678     0.8694      1.071         76        416: 100%|██████████| 21/21 [13:20<00:00, 38.12s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING ⚠️ NMS time limit 8.400s exceeded\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  33%|███▎      | 1/3 [00:36<01:13, 36.84s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING ⚠️ NMS time limit 8.400s exceeded\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [01:28<00:00, 29.56s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        334        503       0.73      0.226      0.232      0.183\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       4/10      8.08G     0.9825      1.099      1.244         78        416: 100%|██████████| 21/21 [15:27<00:00, 44.18s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING ⚠️ NMS time limit 8.400s exceeded\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  33%|███▎      | 1/3 [00:52<01:45, 52.61s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING ⚠️ NMS time limit 8.400s exceeded\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  67%|██████▋   | 2/3 [02:01<01:02, 62.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING ⚠️ NMS time limit 5.900s exceeded\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [03:32<00:00, 70.72s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        334        503        0.4      0.106      0.103     0.0804\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       5/10      7.98G     0.7405     0.8354      1.087         89        416: 100%|██████████| 21/21 [17:36<00:00, 50.29s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING ⚠️ NMS time limit 8.400s exceeded\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  33%|███▎      | 1/3 [00:58<01:56, 58.18s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING ⚠️ NMS time limit 8.400s exceeded\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  67%|██████▋   | 2/3 [01:41<00:49, 49.42s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING ⚠️ NMS time limit 5.900s exceeded\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [02:29<00:00, 49.83s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        334        503      0.657      0.275       0.26      0.196\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       6/10      8.35G     0.4986     0.4561     0.9291         93        416: 100%|██████████| 21/21 [16:31<00:00, 47.21s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING ⚠️ NMS time limit 8.400s exceeded\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  33%|███▎      | 1/3 [01:00<02:01, 60.69s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING ⚠️ NMS time limit 8.400s exceeded\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  67%|██████▋   | 2/3 [02:33<01:19, 79.48s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING ⚠️ NMS time limit 5.900s exceeded\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [03:17<00:00, 65.86s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        334        503      0.771     0.0911      0.106     0.0868\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       7/10      8.43G     0.6086     0.6716      1.022        108        416: 100%|██████████| 21/21 [14:06<00:00, 40.30s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING ⚠️ NMS time limit 8.400s exceeded\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  33%|███▎      | 1/3 [01:05<02:10, 65.14s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING ⚠️ NMS time limit 8.400s exceeded\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [02:07<00:00, 42.62s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        334        503      0.802      0.143      0.164      0.127\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       8/10      8.56G     0.6306     0.6996      1.037         82        416: 100%|██████████| 21/21 [14:07<00:00, 40.36s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING ⚠️ NMS time limit 8.400s exceeded\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  33%|███▎      | 1/3 [01:01<02:02, 61.17s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING ⚠️ NMS time limit 8.400s exceeded\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  67%|██████▋   | 2/3 [01:56<00:57, 57.69s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING ⚠️ NMS time limit 5.900s exceeded\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [02:15<00:00, 45.17s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        334        503      0.877      0.255      0.321      0.293\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       9/10      8.68G     0.4563      0.411     0.9242         74        416: 100%|██████████| 21/21 [13:54<00:00, 39.75s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING ⚠️ NMS time limit 8.400s exceeded\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  33%|███▎      | 1/3 [00:48<01:36, 48.41s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING ⚠️ NMS time limit 8.400s exceeded\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [01:36<00:00, 32.13s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        334        503      0.963      0.441      0.492      0.423\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      10/10      8.83G     0.6746     0.7344      1.078         76        416: 100%|██████████| 21/21 [11:28<00:00, 32.77s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [01:33<00:00, 31.04s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        334        503      0.955      0.965       0.98      0.912\n",
            "\n",
            "10 epochs completed in 2.947 hours.\n",
            "Optimizer stripped from runs/detect/train10/weights/last.pt, 22.5MB\n",
            "Optimizer stripped from runs/detect/train10/weights/best.pt, 22.5MB\n",
            "\n",
            "Validating runs/detect/train10/weights/best.pt...\n",
            "Ultralytics 8.3.88 🚀 Python-3.11.9 torch-2.6.0 MPS (Apple M3)\n",
            "Model summary (fused): 72 layers, 11,126,358 parameters, 0 gradients, 28.4 GFLOPs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [01:23<00:00, 27.93s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        334        503      0.958      0.877      0.925      0.834\n",
            "            Normal Cup        150        240      0.962      0.887      0.933      0.819\n",
            "       Tim Hortons Cup        205        263      0.954      0.867      0.917      0.849\n",
            "Speed: 8.9ms preprocess, 134.9ms inference, 0.0ms loss, 18.7ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/train10\u001b[0m\n",
            "\u001b[34m\u001b[1mMLflow: \u001b[0mresults logged to runs/mlflow\n",
            "\u001b[34m\u001b[1mMLflow: \u001b[0mdisable with 'yolo settings mlflow=False'\n"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "'DetMetrics' object has no attribute 'success'. See valid attributes below.\n\n    Utility class for computing detection metrics such as precision, recall, and mean average precision (mAP) of an\n    object detection model.\n\n    Args:\n        save_dir (Path): A path to the directory where the output plots will be saved. Defaults to current directory.\n        plot (bool): A flag that indicates whether to plot precision-recall curves for each class. Defaults to False.\n        names (dict of str): A dict of strings that represents the names of the classes. Defaults to an empty tuple.\n\n    Attributes:\n        save_dir (Path): A path to the directory where the output plots will be saved.\n        plot (bool): A flag that indicates whether to plot the precision-recall curves for each class.\n        names (dict of str): A dict of strings that represents the names of the classes.\n        box (Metric): An instance of the Metric class for storing the results of the detection metrics.\n        speed (dict): A dictionary for storing the execution time of different parts of the detection process.\n\n    Methods:\n        process(tp, conf, pred_cls, target_cls): Updates the metric results with the latest batch of predictions.\n        keys: Returns a list of keys for accessing the computed detection metrics.\n        mean_results: Returns a list of mean values for the computed detection metrics.\n        class_result(i): Returns a list of values for the computed detection metrics for a specific class.\n        maps: Returns a dictionary of mean average precision (mAP) values for different IoU thresholds.\n        fitness: Computes the fitness score based on the computed detection metrics.\n        ap_class_index: Returns a list of class indices sorted by their average precision (AP) values.\n        results_dict: Returns a dictionary that maps detection metric keys to their computed values.\n        curves: TODO\n        curves_results: TODO\n    ",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[1], line 32\u001b[0m\n\u001b[1;32m     20\u001b[0m results \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mtrain(\n\u001b[1;32m     21\u001b[0m     data\u001b[38;5;241m=\u001b[39myaml_path,       \u001b[38;5;66;03m# Path to the dataset YAML file\u001b[39;00m\n\u001b[1;32m     22\u001b[0m     epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,            \u001b[38;5;66;03m# Number of epochs\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     26\u001b[0m     freeze\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m             \u001b[38;5;66;03m# Freeze the first 10 layers\u001b[39;00m\n\u001b[1;32m     27\u001b[0m )\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# # Clear GPU cache after training\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# torch.mps.empty_cache()\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mresults\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msuccess\u001b[49m:\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining completed! Model saved in YOLO output folder.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/ultralytics/utils/__init__.py:240\u001b[0m, in \u001b[0;36mSimpleClass.__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Custom attribute access error message with helpful information.\"\"\"\u001b[39;00m\n\u001b[1;32m    239\u001b[0m name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n\u001b[0;32m--> 240\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. See valid attributes below.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__doc__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'DetMetrics' object has no attribute 'success'. See valid attributes below.\n\n    Utility class for computing detection metrics such as precision, recall, and mean average precision (mAP) of an\n    object detection model.\n\n    Args:\n        save_dir (Path): A path to the directory where the output plots will be saved. Defaults to current directory.\n        plot (bool): A flag that indicates whether to plot precision-recall curves for each class. Defaults to False.\n        names (dict of str): A dict of strings that represents the names of the classes. Defaults to an empty tuple.\n\n    Attributes:\n        save_dir (Path): A path to the directory where the output plots will be saved.\n        plot (bool): A flag that indicates whether to plot the precision-recall curves for each class.\n        names (dict of str): A dict of strings that represents the names of the classes.\n        box (Metric): An instance of the Metric class for storing the results of the detection metrics.\n        speed (dict): A dictionary for storing the execution time of different parts of the detection process.\n\n    Methods:\n        process(tp, conf, pred_cls, target_cls): Updates the metric results with the latest batch of predictions.\n        keys: Returns a list of keys for accessing the computed detection metrics.\n        mean_results: Returns a list of mean values for the computed detection metrics.\n        class_result(i): Returns a list of values for the computed detection metrics for a specific class.\n        maps: Returns a dictionary of mean average precision (mAP) values for different IoU thresholds.\n        fitness: Computes the fitness score based on the computed detection metrics.\n        ap_class_index: Returns a list of class indices sorted by their average precision (AP) values.\n        results_dict: Returns a dictionary that maps detection metric keys to their computed values.\n        curves: TODO\n        curves_results: TODO\n    "
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Define the output directory and YAML path\n",
        "OUTPUT_DIR = \"/Users/sahilbodkhe/Desktop/Experiment4/SYDE770/Normal_cups/yolo_dataset\"\n",
        "yaml_path = os.path.join(OUTPUT_DIR, \"dataset.yaml\")\n",
        "\n",
        "# Clear GPU cache before starting training\n",
        "if torch.backends.mps.is_available():\n",
        "    torch.mps.empty_cache()\n",
        "    device = \"mps\"\n",
        "else:\n",
        "    device = \"cpu\"  # Fallback to CPU\n",
        "\n",
        "# Load a YOLOv8 model (e.g., yolov8s.pt)\n",
        "model = YOLO(\"yolov8s.pt\")\n",
        "\n",
        "# Train the model\n",
        "results = model.train(\n",
        "    data=yaml_path,       # Path to the dataset YAML file\n",
        "    epochs=10,            # Number of epochs\n",
        "    batch=64,             # Batch size\n",
        "    imgsz=416,            # Image size\n",
        "    device=device,        # Use MPS (Metal Performance Shaders) if available, else CPU\n",
        "    freeze=10             # Freeze the first 10 layers\n",
        ")\n",
        "\n",
        "# # Clear GPU cache after training\n",
        "# torch.mps.empty_cache()\n",
        "\n",
        "# if results.success:\n",
        "#     print(\"Training completed! Model saved in YOLO output folder.\")\n",
        "# # else:\n",
        "#     print(\"Error: YOLO training failed. Check the logs for details.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/ultralytics/__init__.py\n"
          ]
        }
      ],
      "source": [
        "import ultralytics\n",
        "print(ultralytics.__file__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Keeping results ready for MLflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.1.1\n",
            "8.3.88\n"
          ]
        }
      ],
      "source": [
        "import numpy\n",
        "import ultralytics\n",
        "print(numpy.__version__)  # Should print 2.1.1\n",
        "print(ultralytics.__version__)  # Should match 8.3.88\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_box_loss: 0.67455\n",
            "train_dfl_loss: 1.07821\n",
            "train_cls_loss: 0.73439\n",
            "val_box_loss: 0.36067\n",
            "mAP_50: 0.98042\n",
            "mAP_50_95: 0.91239\n",
            "precision: 0.95465\n",
            "recall: 0.96495\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Path to results.csv in latest exp folder\n",
        "latest_exp = '/Users/sahilbodkhe/Desktop/Experiment4/SYDE770/runs/detect/train10'\n",
        "results_path = os.path.join(latest_exp, \"results.csv\")\n",
        "\n",
        "# Check if results.csv exists\n",
        "if os.path.exists(results_path):\n",
        "    df = pd.read_csv(results_path)\n",
        "    df.columns = df.columns.str.strip()\n",
        "\n",
        "    # Extract the values from the last row of the DataFrame\n",
        "    train_box_loss = df.iloc[-1][\"train/box_loss\"]\n",
        "    train_dfl_loss = df.iloc[-1][\"train/dfl_loss\"]  # Corrected column name\n",
        "    train_cls_loss = df.iloc[-1][\"train/cls_loss\"]\n",
        "    val_box_loss = df.iloc[-1][\"val/box_loss\"]\n",
        "    mAP_50 = df.iloc[-1][\"metrics/mAP50(B)\"]  # Corrected column name\n",
        "    mAP_50_95 = df.iloc[-1][\"metrics/mAP50-95(B)\"]  # Corrected column name\n",
        "    precision = df.iloc[-1][\"metrics/precision(B)\"]  # Corrected column name\n",
        "    recall = df.iloc[-1][\"metrics/recall(B)\"]  # Corrected column name\n",
        "\n",
        "    # Print or use the extracted values\n",
        "    print(f\"train_box_loss: {train_box_loss}\")\n",
        "    print(f\"train_dfl_loss: {train_dfl_loss}\")  # Updated variable name\n",
        "    print(f\"train_cls_loss: {train_cls_loss}\")\n",
        "    print(f\"val_box_loss: {val_box_loss}\")\n",
        "    print(f\"mAP_50: {mAP_50}\")\n",
        "    print(f\"mAP_50_95: {mAP_50_95}\")\n",
        "    print(f\"precision: {precision}\")\n",
        "    print(f\"recall: {recall}\")\n",
        "\n",
        "else:\n",
        "    print(f\"Error: {results_path} does not exist.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "ML Flow section"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">                                       <span style=\"font-weight: bold\">❗❗❗ AUTHORIZATION REQUIRED ❗❗❗</span>                                        \n",
              "</pre>\n"
            ],
            "text/plain": [
              "                                       \u001b[1m❗❗❗ AUTHORIZATION REQUIRED ❗❗❗\u001b[0m                                        \n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/rich/live.py:231: UserWarning: \n",
              "install \"ipywidgets\" for Jupyter support\n",
              "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
              "</pre>\n"
            ],
            "text/plain": [
              "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/rich/live.py:231: UserWarning: \n",
              "install \"ipywidgets\" for Jupyter support\n",
              "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Open the following link in your browser to authorize the client:\n",
            "https://dagshub.com/login/oauth/authorize?state=46bc746d-70c3-4d67-81e7-8da7e7067fce&client_id=32b60ba385aa7cecf24046d8195a71c07dd345d9657977863b52e7748e0f0f28&middleman_request_id=ec6b43d9757d4f5bac8e151aa46e6888dab2aeb74e1b2b4115c1bcab4ccf3dea\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Accessing as SAHILBODKHE\n",
              "</pre>\n"
            ],
            "text/plain": [
              "Accessing as SAHILBODKHE\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"chinmay-nagesh/SYDE770-dagshub\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "Initialized MLflow to track repo \u001b[32m\"chinmay-nagesh/SYDE770-dagshub\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository chinmay-nagesh/SYDE770-dagshub initialized!\n",
              "</pre>\n"
            ],
            "text/plain": [
              "Repository chinmay-nagesh/SYDE770-dagshub initialized!\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Metrics and model logged to MLflow.\n",
            "🏃 View run fearless-cat-924 at: https://dagshub.com/chinmay-nagesh/SYDE770-dagshub.mlflow/#/experiments/1/runs/020ca79ae9f24e208e4a8491445f4cf1\n",
            "🧪 View experiment at: https://dagshub.com/chinmay-nagesh/SYDE770-dagshub.mlflow/#/experiments/1\n"
          ]
        }
      ],
      "source": [
        "import mlflow\n",
        "import dagshub\n",
        "import pandas as pd\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "# Initialize MLflow tracking\n",
        "dagshub.init(repo_owner='chinmay-nagesh',\n",
        "             repo_name='SYDE770-dagshub',\n",
        "             mlflow=True)\n",
        "\n",
        "mlflow.set_tracking_uri(\"https://dagshub.com/chinmay-nagesh/SYDE770-dagshub.mlflow\")\n",
        "mlflow.set_experiment(\"YOLOv5 Training\")\n",
        "\n",
        "# Start MLflow run to track hyperparameters and metrics\n",
        "with mlflow.start_run():\n",
        "    # Log Hyperparameters\n",
        "    mlflow.log_param(\"img_size\", 320)\n",
        "    mlflow.log_param(\"batch_size\", 32)\n",
        "    mlflow.log_param(\"epochs\", 5)\n",
        "    mlflow.log_param(\"weights\", \"yolov5s.pt\")\n",
        "    mlflow.log_param(\"device\", \"cpu\")\n",
        "    mlflow.log_param(\"freeze\", 10)\n",
        "    \n",
        "\n",
        "    # Log Metrics\n",
        "    mlflow.log_metric(\"train_box_loss\", train_box_loss)\n",
        "    mlflow.log_metric(\"train_obj_loss\", train_obj_loss)\n",
        "    mlflow.log_metric(\"train_cls_loss\", train_cls_loss)\n",
        "    mlflow.log_metric(\"val_box_loss\", val_box_loss)\n",
        "    mlflow.log_metric(\"mAP_50\", mAP_50)\n",
        "    mlflow.log_metric(\"mAP_50_95\", mAP_50_95)\n",
        "    mlflow.log_metric(\"precision\", precision)\n",
        "    mlflow.log_metric(\"recall\", recall)\n",
        "\n",
        "    # Log Model\n",
        "    best_model_path = \"yolov5/runs/train/exp/weights/best.pt\"\n",
        "    model_save_path = \"yolov5_model\"\n",
        "\n",
        "    if os.path.exists(best_model_path):\n",
        "        os.makedirs(model_save_path, exist_ok=True)\n",
        "        shutil.copy(best_model_path, os.path.join(model_save_path, \"best.pt\"))\n",
        "\n",
        "        # Log Model as an artifact in MLflow\n",
        "        mlflow.log_artifact(os.path.join(model_save_path, \"best.pt\"), artifact_path=\"models/yolov5\")\n",
        "\n",
        "        # Check if model \"yolov5\" exists in MLflow model registry\n",
        "        client = mlflow.tracking.MlflowClient()\n",
        "        model_name = \"yolov8\"\n",
        "\n",
        "        try:\n",
        "            # Try registering a new version of the existing model\n",
        "            mlflow.register_model(f\"runs:/{mlflow.active_run().info.run_id}/models/yolov5/best.pt\", model_name)\n",
        "            print(f\"New version of {model_name} registered in MLflow.\")\n",
        "        except Exception:\n",
        "            # If model does not exist, create a new registered model\n",
        "            mlflow.create_registered_model(model_name)\n",
        "            mlflow.register_model(f\"runs:/{mlflow.active_run().info.run_id}/models/yolov5/best.pt\", model_name)\n",
        "            print(f\"Model {model_name} created and registered in MLflow.\")\n",
        "\n",
        "    print(\"Metrics and model logged to MLflow.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"chinmay-nagesh/SYDE770-dagshub\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "Initialized MLflow to track repo \u001b[32m\"chinmay-nagesh/SYDE770-dagshub\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository chinmay-nagesh/SYDE770-dagshub initialized!\n",
              "</pre>\n"
            ],
            "text/plain": [
              "Repository chinmay-nagesh/SYDE770-dagshub initialized!\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Successfully registered model 'yolov8'.\n",
            "2025/03/13 01:47:31 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: yolov8, version 1\n",
            "Created version '1' of model 'yolov8'.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "New version of yolov8 registered in MLflow.\n",
            "Metrics and model logged to MLflow.\n",
            "🏃 View run angry-owl-868 at: https://dagshub.com/chinmay-nagesh/SYDE770-dagshub.mlflow/#/experiments/1/runs/58aad525607346c8bec8e59feed148ff\n",
            "🧪 View experiment at: https://dagshub.com/chinmay-nagesh/SYDE770-dagshub.mlflow/#/experiments/1\n"
          ]
        }
      ],
      "source": [
        "import mlflow\n",
        "import dagshub\n",
        "import pandas as pd\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "# Initialize MLflow tracking\n",
        "dagshub.init(repo_owner='chinmay-nagesh',\n",
        "             repo_name='SYDE770-dagshub',\n",
        "             mlflow=True)\n",
        "\n",
        "mlflow.set_tracking_uri(\"https://dagshub.com/chinmay-nagesh/SYDE770-dagshub.mlflow\")\n",
        "mlflow.set_experiment(\"YOLOv5 Training\")\n",
        "\n",
        "# Start MLflow run to track hyperparameters and metrics\n",
        "with mlflow.start_run():\n",
        "    # Log Hyperparameters\n",
        "    mlflow.log_param(\"img_size\", 416)\n",
        "    mlflow.log_param(\"batch_size\", 64)\n",
        "    mlflow.log_param(\"epochs\", 10)\n",
        "    mlflow.log_param(\"weights\", \"yolov8s.pt\")\n",
        "    mlflow.log_param(\"device\", \"mps\")\n",
        "    mlflow.log_param(\"freeze\", 10)\n",
        "\n",
        "    # Log Metrics (updated to match the correct column names from the CSV)\n",
        "    mlflow.log_metric(\"train_box_loss\", train_box_loss)\n",
        "    mlflow.log_metric(\"train_dfl_loss\", train_dfl_loss)  # Updated to match CSV column name\n",
        "    mlflow.log_metric(\"train_cls_loss\", train_cls_loss)\n",
        "    mlflow.log_metric(\"val_box_loss\", val_box_loss)\n",
        "    mlflow.log_metric(\"mAP_50\", mAP_50)\n",
        "    mlflow.log_metric(\"mAP_50_95\", mAP_50_95)\n",
        "    mlflow.log_metric(\"precision\", precision)\n",
        "    mlflow.log_metric(\"recall\", recall)  # Fixed typo: \"recall\" instead of \"recall\"\n",
        "\n",
        "    # Log Model\n",
        "    best_model_path = \"runs/detect/train10/weights/best.pt\"\n",
        "    model_save_path = \"yolov8_model\"\n",
        "\n",
        "    if os.path.exists(best_model_path):\n",
        "        os.makedirs(model_save_path, exist_ok=True)\n",
        "        shutil.copy(best_model_path, os.path.join(model_save_path, \"best.pt\"))\n",
        "\n",
        "        # Log Model as an artifact in MLflow\n",
        "        mlflow.log_artifact(os.path.join(model_save_path, \"best.pt\"), artifact_path=\"runs/mlflow/283939179369314934/9f41e2e316dd48ba93ad28a4e2e2ded2/artifacts\")\n",
        "\n",
        "        # Check if model \"yolov5\" exists in MLflow model registry\n",
        "        client = mlflow.tracking.MlflowClient()\n",
        "        model_name = \"yolov8\"  # Corrected model name to match YOLOv5\n",
        "\n",
        "        try:\n",
        "            # Try registering a new version of the existing model\n",
        "            mlflow.register_model(f\"runs:/{mlflow.active_run().info.run_id}/models/yolov8/best.pt\", model_name)\n",
        "            print(f\"New version of {model_name} registered in MLflow.\")\n",
        "        except Exception as e:\n",
        "            # If model does not exist, create a new registered model\n",
        "            print(f\"Error registering model: {e}\")\n",
        "            mlflow.create_registered_model(model_name)\n",
        "            mlflow.register_model(f\"runs:/{mlflow.active_run().info.run_id}/models/yolov8/best.pt\", model_name)\n",
        "            print(f\"Model {model_name} created and registered in MLflow.\")\n",
        "    else:\n",
        "        print(f\"Error: Model file {best_model_path} does not exist.\")\n",
        "\n",
        "    print(\"Metrics and model logged to MLflow.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "image 1/10 /Users/sahilbodkhe/Desktop/Experiment4/SYDE770/Normal_Test/red_paper_cup_with_dark_shade-10.jpeg: 416x416 4 Normal Cups, 63.5ms\n",
            "image 2/10 /Users/sahilbodkhe/Desktop/Experiment4/SYDE770/Normal_Test/red_paper_cup_with_dark_shade-2.jpeg: 416x416 3 Normal Cups, 49.6ms\n",
            "image 3/10 /Users/sahilbodkhe/Desktop/Experiment4/SYDE770/Normal_Test/red_paper_cup_with_dark_shade-3.jpeg: 416x416 2 Normal Cups, 46.9ms\n",
            "image 4/10 /Users/sahilbodkhe/Desktop/Experiment4/SYDE770/Normal_Test/red_paper_cup_with_dark_shade-4.jpeg: 416x416 4 Normal Cups, 50.5ms\n",
            "image 5/10 /Users/sahilbodkhe/Desktop/Experiment4/SYDE770/Normal_Test/red_paper_cup_with_dark_shade-5.jpeg: 416x416 4 Normal Cups, 43.8ms\n",
            "image 6/10 /Users/sahilbodkhe/Desktop/Experiment4/SYDE770/Normal_Test/red_paper_cup_with_dark_shade-6.jpeg: 416x416 3 Normal Cups, 48.3ms\n",
            "image 7/10 /Users/sahilbodkhe/Desktop/Experiment4/SYDE770/Normal_Test/red_paper_cup_with_dark_shade-7.jpeg: 416x416 3 Normal Cups, 44.0ms\n",
            "image 8/10 /Users/sahilbodkhe/Desktop/Experiment4/SYDE770/Normal_Test/red_paper_cup_with_dark_shade-8.jpeg: 416x416 4 Normal Cups, 42.2ms\n",
            "image 9/10 /Users/sahilbodkhe/Desktop/Experiment4/SYDE770/Normal_Test/red_paper_cup_with_dark_shade-9.jpeg: 416x416 3 Normal Cups, 40.9ms\n",
            "image 10/10 /Users/sahilbodkhe/Desktop/Experiment4/SYDE770/Normal_Test/red_paper_cup_with_dark_shade.jpeg: 416x416 2 Normal Cups, 43.7ms\n",
            "Speed: 2.2ms preprocess, 47.3ms inference, 0.3ms postprocess per image at shape (1, 3, 416, 416)\n",
            "Results saved to \u001b[1m/Users/sahilbodkhe/Desktop/Experiment4/SYDE770/predictions/predictions2\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "from ultralytics import YOLO\n",
        "import os\n",
        "import cv2\n",
        "\n",
        "# Path to the trained model\n",
        "model_path = \"/Users/sahilbodkhe/Desktop/Experiment4/SYDE770/runs/detect/train10/weights/best.pt\"\n",
        "\n",
        "# Path to the folder containing test images\n",
        "test_images_folder = \"/Users/sahilbodkhe/Desktop/Experiment4/SYDE770/Test_images\"\n",
        "\n",
        "# Path to save the output images with predictions\n",
        "output_folder = \"/Users/sahilbodkhe/Desktop/Experiment4/SYDE770/predictions\"\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# Load the trained YOLOv8 model\n",
        "model = YOLO(model_path)\n",
        "\n",
        "# Run inference on all images in the Test_images folder\n",
        "results = model.predict(source=test_images_folder, save=True, project=output_folder, name=\"predictions\")\n",
        "\n",
        "# # Function to display images with bounding boxes\n",
        "# def display_images_with_boxes(results, output_folder):\n",
        "#     for result in results:\n",
        "#         # Get the image file name\n",
        "#         image_name = os.path.basename(result.path)\n",
        "#         # Load the output image with bounding boxes\n",
        "#         output_image_path = os.path.join(output_folder, image_name)\n",
        "#         output_image = cv2.imread(output_image_path)\n",
        "        \n",
        "#         # Display the image\n",
        "#         cv2.imshow(\"Prediction\", output_image)\n",
        "#         cv2.waitKey(0)  # Wait for a key press to move to the next image\n",
        "#         cv2.destroyAllWindows()\n",
        "\n",
        "# # Call the function to display images\n",
        "# display_images_with_boxes(results, output_folder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "results = model.predict(source=test_images_folder, conf=0.5, save=True, project=output_folder, name=\"predictions\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
